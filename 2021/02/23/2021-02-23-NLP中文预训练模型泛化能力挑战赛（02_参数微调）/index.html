<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>NLP中文预训练模型泛化能力挑战赛（02 参数微调） | Iyin's blog</title><meta name="description" content="NLP中文预训练模型泛化能力挑战赛"><meta name="keywords" content="自然语言处理,预训练"><meta name="author" content="Iyin,yinwein@foxmail.com"><meta name="copyright" content="Iyin"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/plant.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="NLP中文预训练模型泛化能力挑战赛（02 参数微调）"><meta name="twitter:description" content="NLP中文预训练模型泛化能力挑战赛"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.pn"><meta property="og:type" content="article"><meta property="og:title" content="NLP中文预训练模型泛化能力挑战赛（02 参数微调）"><meta property="og:url" content="http://yoursite.com/2021/02/23/2021-02-23-NLP%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%EF%BC%8802_%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83%EF%BC%89/"><meta property="og:site_name" content="Iyin's blog"><meta property="og:description" content="NLP中文预训练模型泛化能力挑战赛"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.pn"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="canonical" href="http://yoursite.com/2021/02/23/2021-02-23-NLP%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%EF%BC%8802_%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83%EF%BC%89/"><link rel="prev" title="colab使用" href="http://yoursite.com/2021/02/23/2021-02-23-colab%E4%BD%BF%E7%94%A8/"><link rel="next" title="NLP中文预训练模型泛化能力挑战赛（01 Docker提交）" href="http://yoursite.com/2021/02/21/2021-02-21-NLP%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%EF%BC%8801_Docker%E6%8F%90%E4%BA%A4%EF%BC%89/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web:600&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Iyin's blog</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://ae01.alicdn.com/kf/Hb280d3c31450463cb3dc638bf33ca871f.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#改进方案1"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">改进方案1</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#改进方案2"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">改进方案2</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#改进方案1"><span class="toc-number">1.</span> <span class="toc-text">改进方案1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#改进方案2"><span class="toc-number">2.</span> <span class="toc-text">改进方案2</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2020/02/27/3aTBOx.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">NLP中文预训练模型泛化能力挑战赛（02 参数微调）</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2021-02-23<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2021-03-01</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%AB%9E%E8%B5%9B/">竞赛</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><p>太菜了没怎么改 等大佬们改完学习一下继续改</p>
<p>统计输入序列长度，确定序列长度设置256，保证覆盖大多数样本</p>
<ol>
<li><p>修正了get_next_batch()中未处理每个类别数据集==0时没有对于指定变量赋值的问题</p>
</li>
<li><p>修改任务权重</p>
<p>权重计算方法（暂码）</p>
<blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calculate_weight</span><span class="params">(self, kpi, y)</span>:</span></span><br><span class="line">    kpi = max(<span class="number">0.1</span>, kpi)</span><br><span class="line">    kpi = min(<span class="number">0.99</span>, kpi)</span><br><span class="line">    w = <span class="number">-1</span> * ((<span class="number">1</span> - kpi) ** y) * log(kpi)</span><br><span class="line">    <span class="keyword">return</span> w</span><br></pre></td></tr></tbody></table></figure></div>

<p><img alt data-src="/images/2_26_01.png" src="/img/loading.gif" class="lazyload"></p>
<p>参考论文：<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf</a></p>
</blockquote>
<p>参数设置</p>
<blockquote>
<p>所有任务kpi=0.1, y=0.5</p>
<p>这里根据第一次结果 为效果最差的模型ocenmotion赋权kpi = 0.5</p>
</blockquote>
</li>
<li><p>batchsize与accumulation_steps均为16 不再调整</p>
<p>一般batchsize越大，训练越稳定，但是训练会变慢</p>
<blockquote>
<p>一定条件下，batchsize越大训练效果越好，梯度累加则实现了batchsize的变相扩大，如果 accumulation_steps为8，则batchsize变相扩大了8倍，是解决显存受限的一个不错的trick，使用时需要注意，学习率也要适当放大。</p>
<p>来源：<a href="http://www.voidcn.com/article/p-ebyxkjgr-byz.html" target="_blank" rel="noopener">http://www.voidcn.com/article/p-ebyxkjgr-byz.html</a></p>
</blockquote>
</li>
</ol>
<p>跑了5个epoch</p>
<p>baseline加了attention</p>
<h1 id="改进方案1"><a href="#改进方案1" class="headerlink" title="改进方案1"></a>改进方案1</h1><p>来源：<a href="https://www.bilibili.com/video/BV1Yz4y127FM/" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Yz4y127FM/</a></p>
<ol>
<li>将bert的输出输入树模型</li>
<li>模型输入两个子句</li>
<li>共享bert参数，不同任务使用不同输出层</li>
<li>进一步优化参数</li>
<li>每个batch_size包含各个类别 自定义loss计算</li>
</ol>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#一些调优参数</span><br><span class="line">er_patience = 2 #early_stopping patience</span><br><span class="line">lr_patience = 5 #ReduceLROnPlateau patience</span><br><span class="line">max_epochs = 3 #epochs</span><br><span class="line">lr_rate = 3e-6 #learning rate</span><br><span class="line">batch_sz = 4  #batch_size</span><br><span class="line">maxlen = 256  #设置序列长度为，base模型要保证序列长度不超过512</span><br><span class="line">lr_factor = 0.85 #ReduceLROnPlateau factor，lr*=factor</span><br><span class="line">maxlentext1 = 200 #选择ocnli子句一的长度</span><br><span class="line">n_folds = 10   #设置验证集的占比: 1/n_folds</span><br><span class="line">#ReduceLROnPlateau其他参数：https://keras.io/zh/callbacks/#reducelronplateau</span><br></pre></td></tr></tbody></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">path_bert = path + '/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/'</span><br><span class="line">#预训练好的模型相关路径</span><br><span class="line">config_path = path_bert + 'bert_config.json'</span><br><span class="line">dict_path   = path_bert + 'vocab.txt'</span><br><span class="line">checkpoint_path = path_bert + 'bert_model.ckpt'</span><br></pre></td></tr></tbody></table></figure></div>

<p>分层抽样：分类任务每一个类别抽取相应比例的样本</p>
<h1 id="改进方案2"><a href="#改进方案2" class="headerlink" title="改进方案2"></a>改进方案2</h1><p>来源：<a href="https://github.com/finlay-liu/tianchi-multi-task-nlp" target="_blank" rel="noopener">https://github.com/finlay-liu/tianchi-multi-task-nlp</a></p>
<ol>
<li>修改 calculate_loss.py 改变loss的计算方式，从平衡子任务难度以及各子任务类别样本不均匀入手；</li>
<li>修改 net.py 改变模型的结构，加入attention层，或者其他层；</li>
<li>使用 cleanlab 等工具对训练文本进行清洗；</li>
<li>做文本数据增强，或者在预训练时候用其他数据集pretrain；</li>
<li>对训练好的模型再在完整数据集（包括验证集和训练集）上用小的学习率训练一个epoch；</li>
<li>调整bathSize和a_step，变更梯度累计的程度，当前是batchSize=16，a_step=16；</li>
<li>用 chinese-roberta-wwm-ext 作为预训练模型；</li>
</ol>
</body></html></div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理    </a><a class="post-meta__tags" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/">预训练    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.pn" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2021/02/23/2021-02-23-colab%E4%BD%BF%E7%94%A8/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>colab使用</span></div></a></div><div class="next-post pull_right"><a href="/2021/02/21/2021-02-21-NLP%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%EF%BC%8801_Docker%E6%8F%90%E4%BA%A4%EF%BC%89/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>NLP中文预训练模型泛化能力挑战赛（01 Docker提交）</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/02/21/2021-02-21-NLP中文预训练模型泛化能力挑战赛（01_Docker提交）/" title="NLP中文预训练模型泛化能力挑战赛（01 Docker提交）"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-02-21</div><div class="relatedPosts_title">NLP中文预训练模型泛化能力挑战赛（01 Docker提交）</div></div></a></div><div class="relatedPosts_item"><a href="/2021/08/15/2021-08-15-基于transformers的自然语言处理(NLP)入门1/" title="（一）Transformers在NLP中的兴起"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-08-15</div><div class="relatedPosts_title">（一）Transformers在NLP中的兴起</div></div></a></div><div class="relatedPosts_item"><a href="/2021/08/18/2021-08-18-基于transformers的自然语言处理(NLP)入门2.1/" title="2.1 Attention"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-08-18</div><div class="relatedPosts_title">2.1 Attention</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Iyin</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script id="canvas_nest" color="189,207,69" opacity="0.9" zIndex="-1" count="70" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>