<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Tensorflow进阶 | Iyin's blog</title><meta name="description" content="《Tensorflow深度学习》unit5"><meta name="keywords" content="Deep Learning,Tensorflow"><meta name="author" content="Iyin,yinwein@foxmail.com"><meta name="copyright" content="Iyin"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/plant.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Tensorflow进阶"><meta name="twitter:description" content="《Tensorflow深度学习》unit5"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta property="og:type" content="article"><meta property="og:title" content="Tensorflow进阶"><meta property="og:url" content="http://yoursite.com/2020/02/27/2020-02-27-unit5/"><meta property="og:site_name" content="Iyin's blog"><meta property="og:description" content="《Tensorflow深度学习》unit5"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="canonical" href="http://yoursite.com/2020/02/27/2020-02-27-unit5/"><link rel="prev" title="Tensorflow基础" href="http://yoursite.com/2020/02/27/2020-02-27-unit4/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web:600&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Iyin's blog</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://ae01.alicdn.com/kf/Hb280d3c31450463cb3dc638bf33ca871f.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">11</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#《Tensorflow深度学习》unit5学习记录"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">《Tensorflow深度学习》unit5学习记录</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#合并与分割"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">合并与分割</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据统计"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">数据统计</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#填充与复制"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">填充与复制</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据限幅"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">数据限幅</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#高级操作"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text">高级操作</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#《Tensorflow深度学习》unit5学习记录"><span class="toc-number">1.</span> <span class="toc-text">《Tensorflow深度学习》unit5学习记录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#合并与分割"><span class="toc-number">1.1.</span> <span class="toc-text">合并与分割</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据统计"><span class="toc-number">1.2.</span> <span class="toc-text">数据统计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#填充与复制"><span class="toc-number">1.3.</span> <span class="toc-text">填充与复制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据限幅"><span class="toc-number">1.4.</span> <span class="toc-text">数据限幅</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#高级操作"><span class="toc-number">1.5.</span> <span class="toc-text">高级操作</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2020/02/27/3aTBOx.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">Tensorflow进阶</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-02-27<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-02-27</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><h1 id="《Tensorflow深度学习》unit5学习记录"><a href="#《Tensorflow深度学习》unit5学习记录" class="headerlink" title="《Tensorflow深度学习》unit5学习记录"></a>《Tensorflow深度学习》unit5学习记录</h1><h2 id="合并与分割"><a href="#合并与分割" class="headerlink" title="合并与分割"></a>合并与分割</h2><ul>
<li>合并<ul>
<li>拼接：在现有维度上合并。</li>
<li>堆叠：创建新维度。</li>
</ul>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 拼接</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">35</span>,<span class="number">8</span>]) <span class="comment"># 模拟成绩册A</span></span><br><span class="line">b = tf.random.normal([<span class="number">6</span>,<span class="number">35</span>,<span class="number">8</span>]) <span class="comment"># 模拟成绩册B</span></span><br><span class="line">tf.concat([a,b],axis=<span class="number">0</span>).shape <span class="comment"># 拼接合并成绩册</span></span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>TensorShape([10, 35, 8])</code></pre><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 堆叠</span></span><br><span class="line">a = tf.random.normal([<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">b = tf.random.normal([<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">tf.stack([a,b],axis=<span class="number">0</span>).shape <span class="comment"># 堆叠合并为2 个班级，班级维度插入在最前</span></span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>TensorShape([2, 35, 8])</code></pre><ul>
<li>分割<ul>
<li>result = tf.split(x, num_or_size_splits=10, axis=0)</li>
<li>在某个维度上全部按长度为1的方式分割 tf.unstack(x,axis)</li>
</ul>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">10</span>,<span class="number">35</span>,<span class="number">8</span>])</span><br><span class="line">result = tf.split(x, <span class="number">10</span>, <span class="number">0</span>)</span><br><span class="line">len(result),result[<span class="number">0</span>].shape</span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>(10, TensorShape([1, 35, 8]))</code></pre><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">result = tf.split(x, num_or_size_splits=[<span class="number">4</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>] ,axis=<span class="number">0</span>)</span><br><span class="line">len(result),result[<span class="number">0</span>].shape</span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>(4, TensorShape([4, 35, 8]))</code></pre><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">result = tf.unstack(x,axis=<span class="number">0</span>) <span class="comment"># Unstack 为长度为1 的张量</span></span><br><span class="line">len(result),result[<span class="number">0</span>].shape <span class="comment">#少了被分割的维度</span></span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>(10, TensorShape([35, 8]))</code></pre><h2 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h2><p>1.<strong>向量范数Vector Norm</strong></p>
<ul>
<li><strong>tf.norm(x, ord)</strong></li>
<li>概念<ul>
<li>表征向量“长度”的一种度量方法，可以推广到张量上。</li>
<li>常用来表示张量的权值大小，梯度大小等。</li>
</ul>
</li>
<li>常用的向量范数<ul>
<li>L1 范数，ord = 1，定义为向量𝒙的所有元素绝对值之和</li>
<li>L2 范数，ord = 2，定义为向量𝒙的所有元素的平方和，再开根号</li>
<li>∞ −范数，ord = np.inf，定义为向量𝒙的所有元素绝对值的最大值</li>
</ul>
</li>
<li>对于矩阵和张量，同样可以利用向量范数的计算公式，等价于将矩阵和张量打平成向量后计算。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.ones([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">tf.norm(x,ord=<span class="number">2</span>) <span class="comment"># 计算L2 范数</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="129," shape="()," dtype="float32," numpy="2.0"></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">tf.norm(x,ord=np.inf) <span class="comment"># 计算∞范数</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="133," shape="()," dtype="float32," numpy="1.0"></tf.tensor:></p>
<p>2.<strong>最值、均值、和</strong></p>
<ul>
<li>tf.reduce_max、tf.reduce_min、tf.reduce_mean、tf.reduce_sum</li>
<li>可以求解张量在某个维度上的最大、最小、均值、和，也可以求全局最大、最小、均值、和。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x =  tf.random.normal([<span class="number">4</span>,<span class="number">10</span>])</span><br><span class="line">tf.reduce_max(x,axis=<span class="number">1</span>) <span class="comment">#维度1上的最大值</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="144," shape="(4,)," dtype="float32," numpy="array([1.1141267" , 0.42764485, 1.2535464 0.86920667],></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 不指定维度，求全局</span></span><br><span class="line">tf.reduce_max(x),tf.reduce_min(x),tf.reduce_mean(x)</span><br></pre></td></tr></tbody></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">markdown</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight markdown"><table><tbody><tr><td class="code"><pre><span class="line">(<span class="xml"><span class="tag"><<span class="name">tf.Tensor:</span> <span class="attr">id</span>=<span class="string">146,</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">1.2535464</span>></span></span>,</span><br><span class="line"> <span class="xml"><span class="tag"><<span class="name">tf.Tensor:</span> <span class="attr">id</span>=<span class="string">148,</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">-2.0888348</span>></span></span>,</span><br><span class="line"> <span class="xml"><span class="tag"><<span class="name">tf.Tensor:</span> <span class="attr">id</span>=<span class="string">150,</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">-0.34670228</span>></span></span>)</span><br></pre></td></tr></tbody></table></figure></div>


<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">out = tf.random.normal([<span class="number">4</span>,<span class="number">10</span>]) <span class="comment"># 模拟网络预测输出</span></span><br><span class="line">y = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>]) <span class="comment"># 模拟真实标签</span></span><br><span class="line">y = tf.one_hot(y,depth=<span class="number">10</span>) <span class="comment"># one-hot 编码</span></span><br><span class="line">loss = keras.losses.mse(y,out) <span class="comment"># 计算每个样本的误差</span></span><br><span class="line">loss = tf.reduce_mean(loss) <span class="comment"># 平均误差，在样本数维度上取均值</span></span><br><span class="line">loss <span class="comment"># 误差标量</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="177," shape="()," dtype="float32," numpy="1.1329651"></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 获得索引</span></span><br><span class="line">out = tf.random.normal([<span class="number">2</span>,<span class="number">10</span>])</span><br><span class="line">out = tf.nn.softmax(out, axis=<span class="number">1</span>) <span class="comment"># 通过softmax 函数转换为概率值</span></span><br><span class="line">pred = tf.argmax(out, axis=<span class="number">1</span>) <span class="comment"># 选取概率最大的位置</span></span><br><span class="line">pred <span class="comment">#两个样本的最大值分别出现在3、5上</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="216," shape="(2,)," dtype="int64," numpy="array([3," 5],></tf.tensor:></p>
<p>3.张量比较</p>
<ul>
<li>tf.math.greater</li>
<li>tf.math.less</li>
<li>tf.math.greater_equal</li>
<li>tf.math.less_equal</li>
<li>tf.math.note_equal</li>
<li>tf.math.is_nan</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">out = tf.random.normal([<span class="number">100</span>,<span class="number">10</span>])</span><br><span class="line">out = tf.nn.softmax(out, axis=<span class="number">1</span>) <span class="comment"># 输出转换为概率</span></span><br><span class="line">pred = tf.argmax(out, axis=<span class="number">1</span>) <span class="comment"># 计算预测值</span></span><br><span class="line">pred</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="234," shape="(100,)," dtype="int64," numpy="<br">array([8, 7, 3, 5, 9, 8, 9, 1, 6, 9, 2, 6, 6, 0, 6, 8, 5, 3, 1, 3, 1, 5,<br>       2, 8, 2, 6, 2, 6, 2, 7, 3, 3, 7, 4, 0, 3, 1, 5, 8, 2, 8, 7, 8, 4,<br>       3, 0, 8, 8, 5, 2, 0, 2, 4, 9, 4, 5, 6, 3, 8, 0, 1, 1, 6, 8, 9, 7,<br>       6, 2, 8, 6, 7, 3, 6, 5, 7, 6, 7, 2, 8, 3, 0, 7, 5, 6, 6, 8, 6, 9,<br>       5, 6, 2, 1, 6, 8, 1, 1, 6, 8, 1, 0], dtype=int64)></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">y = tf.random.uniform([<span class="number">100</span>], dtype = tf.int64, maxval = <span class="number">10</span>) <span class="comment"># ，模拟真实值</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="242," shape="(100,)," dtype="int64," numpy="<br">array([0, 8, 1, 7, 3, 7, 8, 2, 6, 1, 4, 2, 5, 0, 0, 6, 4, 7, 5, 8, 5, 0,<br>       0, 4, 6, 9, 8, 7, 1, 7, 7, 3, 7, 2, 2, 5, 6, 4, 9, 9, 1, 3, 9, 3,<br>       7, 0, 8, 4, 4, 5, 4, 0, 1, 0, 8, 9, 8, 7, 3, 2, 3, 5, 3, 5, 7, 5,<br>       2, 8, 2, 7, 4, 8, 5, 1, 5, 7, 9, 1, 7, 6, 3, 1, 7, 5, 8, 3, 9, 5,<br>       3, 3, 3, 5, 4, 8, 7, 7, 7, 3, 6, 5], dtype=int64)></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">out = tf.equal(pred,y) <span class="comment"># 预测值与真实值比较，返回布尔类型的张量</span></span><br><span class="line">out</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="257," shape="(100,)," dtype="bool," numpy="<br">array([False, False, False, False, False, False, False, False,  True,<br>       False, False, False, False,  True, False, False, False, False,<br>       False, False, False, False, False, False, False, False, False,<br>       False, False,  True, False,  True,  True, False, False, False,<br>       False, False, False, False, False, False, False, False, False,<br>        True,  True, False, False, False, False, False, False, False,<br>       False, False, False, False, False, False, False, False, False,<br>       False, False, False, False, False, False, False, False, False,<br>       False, False, False, False, False, False, False, False, False,<br>       False, False, False, False, False, False, False, False, False,<br>       False, False, False,  True, False, False, False, False, False,<br>       False])></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">out = tf.cast(out, dtype=tf.float32) <span class="comment"># 布尔型转int 型</span></span><br><span class="line">correct = tf.reduce_sum(out) <span class="comment"># 统计True 的个数</span></span><br><span class="line">correct.numpy()</span><br></pre></td></tr></tbody></table></figure></div>

<p>8.0</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">accuracy = correct/<span class="number">100</span></span><br><span class="line">accuracy.numpy()</span><br></pre></td></tr></tbody></table></figure></div>

<p>0.08</p>
<h2 id="填充与复制"><a href="#填充与复制" class="headerlink" title="填充与复制"></a>填充与复制</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]) <span class="comment"># 第一个句子</span></span><br><span class="line">b = tf.constant([<span class="number">7</span>,<span class="number">8</span>,<span class="number">1</span>,<span class="number">6</span>]) <span class="comment"># 第二个句子</span></span><br><span class="line">b = tf.pad(b, [[<span class="number">0</span>,<span class="number">2</span>]]) <span class="comment"># 句子末尾填充2 个0</span></span><br></pre></td></tr></tbody></table></figure></div>


<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tf.stack([a,b],axis = <span class="number">0</span>)<span class="comment">#创建句子维度</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="262," shape="(2," 6), dtype="int32," numpy="<br">array([[1, 2, 3, 4, 5, 6],<br>       [7, 8, 1, 6, 0, 0]])></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">total_words = <span class="number">10000</span> <span class="comment"># 设定词汇量大小</span></span><br><span class="line">max_review_len = <span class="number">80</span> <span class="comment"># 最大句子长度</span></span><br><span class="line">embedding_len = <span class="number">100</span> <span class="comment"># 词向量长度</span></span><br></pre></td></tr></tbody></table></figure></div>


<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 将句子填充或截断到相同长度，设置为末尾填充truncating和末尾截断方式padding</span></span><br><span class="line"><span class="comment"># pre/post</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = \</span><br><span class="line">keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">x_train = \</span><br><span class="line">keras.preprocessing.sequence.pad_sequences \</span><br><span class="line">(x_train, maxlen=max_review_len,truncating=<span class="string">'post'</span>,padding=<span class="string">'post'</span>)</span><br><span class="line"></span><br><span class="line">x_test = \</span><br><span class="line">keras.preprocessing.sequence.pad_sequences \</span><br><span class="line">(x_test, maxlen=max_review_len,truncating=<span class="string">'post'</span>,padding=<span class="string">'post'</span>)</span><br><span class="line"></span><br><span class="line">print(x_train.shape, x_test.shape) <span class="comment"># 打印等长的句子张量形状</span></span><br></pre></td></tr></tbody></table></figure></div>

<pre><code>(25000, 80) (25000, 80)</code></pre><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 第2、3个维度，左右各填充2单元</span></span><br><span class="line"><span class="comment"># tf.pad(x,[[0,0],[2,2],[2,2],[0,0]])</span></span><br></pre></td></tr></tbody></table></figure></div>


<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line">tf.tile(x,[<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>]).shape <span class="comment"># 数据复制</span></span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>TensorShape([8, 96, 96, 3])</code></pre><h2 id="数据限幅"><a href="#数据限幅" class="headerlink" title="数据限幅"></a>数据限幅</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 实现ReLU 函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(u)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.maximum(x, <span class="number">0.</span>)</span><br></pre></td></tr></tbody></table></figure></div>


<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tf.minimum(x,<span class="number">7</span>) <span class="comment"># 上限幅到7</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="292," shape="(9,)," dtype="int32," numpy="array([0," 1, 2, 3, 4, 5, 6, 7, 7])></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.range(<span class="number">9</span>)</span><br><span class="line"><span class="comment"># tf.minimum(tf.maximum(x,2),7) # 限幅为2~7</span></span><br><span class="line">tf.clip_by_value(x,<span class="number">2</span>,<span class="number">7</span>) <span class="comment"># 限幅为2~7</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="308," shape="(9,)," dtype="int32," numpy="array([2," 2, 3, 4, 5, 6, 7, 7])></tf.tensor:></p>
<h2 id="高级操作"><a href="#高级操作" class="headerlink" title="高级操作"></a>高级操作</h2><p>根据索引号收集数据</p>
<ul>
<li>tf.gather 指定维度，获取对应全部数据</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">4</span>,<span class="number">35</span>,<span class="number">8</span>],maxval=<span class="number">100</span>,dtype=tf.int32) <span class="comment"># 成绩册张量</span></span><br><span class="line">tf.gather(x,[<span class="number">0</span>,<span class="number">3</span>,<span class="number">8</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">26</span>],axis=<span class="number">0</span>).shape</span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>TensorShape([6, 35, 8])</code></pre><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 切片</span></span><br><span class="line"><span class="comment"># x [:2] # 在班级维度收集第1~2 号班级成绩册</span></span><br></pre></td></tr></tbody></table></figure></div>

<ul>
<li>tf.gather_nd 指定每个维度，获取对应维度对应索引数据</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># tf.stack([x[1,1],x[2,2],x[3,3]],axis=0)</span></span><br><span class="line">tf.gather_nd(x,[[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="comment"># tf.gather_nd(x,[[1,1,2],[2,2,3],[3,3,4]])</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="335," shape="(3," 8), dtype="int32," numpy="<br">array([[29, 28, 39, 61, 98, 76, 47, 61],<br>       [75, 61,  1, 40,  4, 55, 92, 15],<br>       [53,  9, 31, 80,  3, 20, 39, 18]])></tf.tensor:></p>
<ul>
<li>tf.boolean_mask 通过掩码方式采样</li>
<li>tf.boolean_mask_nd</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tf.boolean_mask(x,mask=[<span class="literal">True</span>, <span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>],axis=<span class="number">0</span>).shape</span><br><span class="line"><span class="comment"># 注意掩码的长度必须与对应维度的长度一致</span></span><br></pre></td></tr></tbody></table></figure></div>


<pre><code>TensorShape([2, 35, 8])</code></pre><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">2</span>,<span class="number">3</span>,<span class="number">8</span>],maxval=<span class="number">100</span>,dtype=tf.int32)</span><br><span class="line">tf.boolean_mask(x,[[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>],[<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">True</span>]])</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="451," shape="(4," 8), dtype="int32," numpy="<br">array([[51, 38, 69, 60, 46, 77, 88,  2],<br>       [45, 36, 97, 58, 42, 10, 77, 28],<br>       [36, 54, 23, 39, 90, 41, 88, 92],<br>       [ 7, 17, 35, 24, 66, 49, 27, 33]])></tf.tensor:></p>
<ul>
<li>tf.where(cond, a, b)操作可以根据cond 条件的真假从参数𝑨或𝑩中读取数据</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">a = tf.ones([<span class="number">3</span>,<span class="number">3</span>]) <span class="comment"># 构造a 为全1 矩阵</span></span><br><span class="line">b = tf.zeros([<span class="number">3</span>,<span class="number">3</span>]) <span class="comment"># 构造b 为全0 矩阵</span></span><br><span class="line"><span class="comment"># 构造采样条件 其中cond𝑖为True 的位置从𝑨中对应位置提取元素，反之从B提取元素</span></span><br><span class="line">cond = \</span><br><span class="line">tf.constant([[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>],[<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">False</span>],[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>]])</span><br><span class="line">tf.where(cond,a,b) <span class="comment"># 根据条件从a,b 中采样</span></span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="459," shape="(3," 3), dtype="float32," numpy="<br">array([[1., 0., 0.],<br>       [0., 1., 0.],<br>       [1., 1., 0.]], dtype=float32)></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 当参数a=b=None时，即a和b参数不指定</span></span><br><span class="line"><span class="comment"># tf.where 会返回cond 张量中所有True的元素的索引坐标</span></span><br><span class="line"><span class="comment"># 提取张量中所有正数数据及索引</span></span><br><span class="line">x = tf.random.normal([<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">mask=x><span class="number">0</span> <span class="comment"># 比较操作，等同于tf.math.greater()</span></span><br><span class="line">mask</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="476," shape="(3," 3), dtype="bool," numpy="<br">array([[ True, False, False],<br>       [False, False,  True],<br>       [ True,  True, False]])></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 方法一：通过索引提取正数的元素值</span></span><br><span class="line">indices=tf.where(mask) <span class="comment"># 提取所有大于0 的元素索引</span></span><br><span class="line">tf.gather_nd(x,indices) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二：通过掩码提取正数的元素值</span></span><br><span class="line">tf.boolean_mask(x,mask)</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="478," shape="(4,)," dtype="float32," numpy="array([0.8831726" , 1.112463 1.6572974 0.42189097],></tf.tensor:></p>
<ul>
<li>scatter_ndnd(indices, updates, shape)函数可以高效地刷新张量的部分数据</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 向量刷新</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造需要刷新数据的位置参数，即为4、3、1 和7 号位置</span></span><br><span class="line">indices = tf.constant([[<span class="number">4</span>], [<span class="number">3</span>], [<span class="number">1</span>], [<span class="number">7</span>]])</span><br><span class="line"><span class="comment"># 构造需要写入的数据，4 号位写入4.4,3 号位写入3.3，以此类推</span></span><br><span class="line">updates = tf.constant([<span class="number">4.4</span>, <span class="number">3.3</span>, <span class="number">1.1</span>, <span class="number">7.7</span>])</span><br><span class="line"><span class="comment"># 在长度为8 的全0 向量上根据indices 写入updates 数据</span></span><br><span class="line">tf.scatter_nd(indices, updates, [<span class="number">8</span>])</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="482," shape="(8,)," dtype="float32," numpy="array([0." , 1.1, 0. 3.3, 4.4, 7.7],></tf.tensor:></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 3 维张量的刷新</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造写入位置，即2 个位置</span></span><br><span class="line">indices = tf.constant([[<span class="number">1</span>],[<span class="number">3</span>]])</span><br><span class="line">updates = tf.constant([<span class="comment"># 构造写入数据，即2 个矩阵</span></span><br><span class="line">[[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>]],</span><br><span class="line">[[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>]]])</span><br><span class="line"><span class="comment"># 在shape 为[4,4,4]白板上根据indices 写入updates</span></span><br><span class="line">tf.scatter_nd(indices,updates,[<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>])</span><br></pre></td></tr></tbody></table></figure></div>

<p><tf.tensor: id="486," shape="(4," 4, 4), dtype="int32," numpy="<br">array([[[0, 0, 0, 0],<br>        [0, 0, 0, 0],<br>        [0, 0, 0, 0],<br>        [0, 0, 0, 0]],</tf.tensor:></p>
<p>​       [[5, 5, 5, 5],<br>​        [6, 6, 6, 6],<br>​        [7, 7, 7, 7],<br>​        [8, 8, 8, 8]],</p>
<p>​       [[0, 0, 0, 0],<br>​        [0, 0, 0, 0],<br>​        [0, 0, 0, 0],<br>​        [0, 0, 0, 0]],</p>
<p>​       [[1, 1, 1, 1],<br>​        [2, 2, 2, 2],<br>​        [3, 3, 3, 3],<br>​        [4, 4, 4, 4]]])></p>
<ul>
<li>tf.meshgrid 函数可以方便地生成二维网格的采样点坐标，方便可视化等应用场合</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = tf.linspace(<span class="number">-8.</span>,<span class="number">8</span>,<span class="number">100</span>) <span class="comment"># 设置x 轴的采样点</span></span><br><span class="line">y = tf.linspace(<span class="number">-8.</span>,<span class="number">8</span>,<span class="number">100</span>) <span class="comment"># 设置y 轴的采样点</span></span><br><span class="line">x,y = tf.meshgrid(x,y) <span class="comment"># 生成网格点，并内部拆分后返回</span></span><br><span class="line">x.shape,y.shape <span class="comment"># 打印拆分后的所有点的x,y 坐标张量shape</span></span><br><span class="line"></span><br><span class="line">z = tf.sqrt(x**<span class="number">2</span>+y**<span class="number">2</span>)</span><br><span class="line">z = tf.sin(z)/z <span class="comment"># sinc 函数实现</span></span><br></pre></td></tr></tbody></table></figure></div>


<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 导入3D 坐标轴支持</span></span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig) <span class="comment"># 设置3D 坐标轴</span></span><br><span class="line"><span class="comment"># 根据网格点绘制sinc 函数3D 曲面</span></span><br><span class="line">ax.contour3D(x.numpy(), y.numpy(), z.numpy(), <span class="number">50</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure></div>


<p><img alt="png" data-src="https://s2.ax1x.com/2020/02/27/3wiBVS.png" src="/img/loading.gif" class="lazyload"></p>
</body></html></div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning    </a><a class="post-meta__tags" href="/tags/Tensorflow/">Tensorflow    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-full"><a href="/2020/02/27/2020-02-27-unit4/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>Tensorflow基础</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/03/03/2020-03-03-unit6/" title="神经网络"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-03</div><div class="relatedPosts_title">神经网络</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/27/2020-02-27-unit4/" title="Tensorflow基础"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-27</div><div class="relatedPosts_title">Tensorflow基础</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Iyin</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script id="canvas_nest" color="189,207,69" opacity="0.9" zIndex="-1" count="70" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>