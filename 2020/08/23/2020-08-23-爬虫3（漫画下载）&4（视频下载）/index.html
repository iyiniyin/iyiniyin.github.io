<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>爬虫3（漫画下载）&amp;4（视频下载） | Iyin's blog</title><meta name="description" content="爬虫学习笔记"><meta name="keywords" content="爬虫"><meta name="author" content="Iyin,yinwein@foxmail.com"><meta name="copyright" content="Iyin"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/plant.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="爬虫3（漫画下载）&amp;4（视频下载）"><meta name="twitter:description" content="爬虫学习笔记"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta property="og:type" content="article"><meta property="og:title" content="爬虫3（漫画下载）&amp;4（视频下载）"><meta property="og:url" content="http://yoursite.com/2020/08/23/2020-08-23-%E7%88%AC%E8%99%AB3%EF%BC%88%E6%BC%AB%E7%94%BB%E4%B8%8B%E8%BD%BD%EF%BC%89&amp;4%EF%BC%88%E8%A7%86%E9%A2%91%E4%B8%8B%E8%BD%BD%EF%BC%89/"><meta property="og:site_name" content="Iyin's blog"><meta property="og:description" content="爬虫学习笔记"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="canonical" href="http://yoursite.com/2020/08/23/2020-08-23-%E7%88%AC%E8%99%AB3%EF%BC%88%E6%BC%AB%E7%94%BB%E4%B8%8B%E8%BD%BD%EF%BC%89&amp;4%EF%BC%88%E8%A7%86%E9%A2%91%E4%B8%8B%E8%BD%BD%EF%BC%89/"><link rel="prev" title="蛋壳公寓租房信息爬取" href="http://yoursite.com/2020/11/21/2020-11-21-%E8%9B%8B%E5%A3%B3%E5%85%AC%E5%AF%93%E7%A7%9F%E6%88%BF%E4%BF%A1%E6%81%AF%E7%88%AC%E5%8F%96/"><link rel="next" title="爬虫1&amp;2（小说下载）" href="http://yoursite.com/2020/08/22/2020-08-22-%E7%88%AC%E8%99%AB1&amp;2%EF%BC%88%E5%B0%8F%E8%AF%B4%E4%B8%8B%E8%BD%BD%EF%BC%89/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web:600&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Iyin's blog</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://ae01.alicdn.com/kf/Hb280d3c31450463cb3dc638bf33ca871f.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">11</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#（一）初识网络爬虫"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">（一）初识网络爬虫</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#简介"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">简介</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#URL——uniform-resource-locator"><span class="toc_mobile_items-number">1.1.1.</span> <span class="toc_mobile_items-text">URL——uniform resource locator</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#审查元素"><span class="toc_mobile_items-number">1.1.2.</span> <span class="toc_mobile_items-text">审查元素</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#基本方法"><span class="toc_mobile_items-number">1.1.3.</span> <span class="toc_mobile_items-text">基本方法</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#（二）网络小说下载"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">（二）网络小说下载</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#爬虫步骤"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">爬虫步骤</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#爬取小说内容"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">爬取小说内容</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#发起请求"><span class="toc_mobile_items-number">2.2.1.</span> <span class="toc_mobile_items-text">发起请求</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#解析数据"><span class="toc_mobile_items-number">2.2.2.</span> <span class="toc_mobile_items-text">解析数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#整合代码，保存数据"><span class="toc_mobile_items-number">2.2.3.</span> <span class="toc_mobile_items-text">整合代码，保存数据</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#（一）初识网络爬虫"><span class="toc-number">1.</span> <span class="toc-text">（一）初识网络爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#URL——uniform-resource-locator"><span class="toc-number">1.1.1.</span> <span class="toc-text">URL——uniform resource locator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#审查元素"><span class="toc-number">1.1.2.</span> <span class="toc-text">审查元素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基本方法"><span class="toc-number">1.1.3.</span> <span class="toc-text">基本方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#（二）网络小说下载"><span class="toc-number">2.</span> <span class="toc-text">（二）网络小说下载</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#爬虫步骤"><span class="toc-number">2.1.</span> <span class="toc-text">爬虫步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬取小说内容"><span class="toc-number">2.2.</span> <span class="toc-text">爬取小说内容</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#发起请求"><span class="toc-number">2.2.1.</span> <span class="toc-text">发起请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解析数据"><span class="toc-number">2.2.2.</span> <span class="toc-text">解析数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#整合代码，保存数据"><span class="toc-number">2.2.3.</span> <span class="toc-text">整合代码，保存数据</span></a></li></ol></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2020/02/27/3aTBOx.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">爬虫3（漫画下载）&amp;4（视频下载）</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-08-23<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-08-25</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><p>参考：</p>
<ul>
<li><p><a href="https://blog.csdn.net/c406495762/article/details/105648001" target="_blank" rel="noopener">https://blog.csdn.net/c406495762/article/details/105648001</a> </p>
</li>
<li><p><a href="https://blog.csdn.net/c406495762/article/details/105797795" target="_blank" rel="noopener">https://blog.csdn.net/c406495762/article/details/105797795</a> </p>
</li>
</ul>
<h1 id="（一）初识网络爬虫"><a href="#（一）初识网络爬虫" class="headerlink" title="（一）初识网络爬虫"></a>（一）初识网络爬虫</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>根据网页地址（URL）爬取网页内容 </p>
<h3 id="URL——uniform-resource-locator"><a href="#URL——uniform-resource-locator" class="headerlink" title="URL——uniform resource locator"></a>URL——uniform resource locator</h3><p>*<em>【一般格式】protocol :// hostname[:port] / path / [;parameters][?query]#fragment *</em></p>
<p>主要由前三个部分组成：</p>
<ul>
<li><strong>protocol</strong>：协议，例如https协议 </li>
<li><strong>hostname[:port]</strong>：主机名（还有端口号为可选参数），一般网站默认的端口号为80，例如百度的主机名就是<a href="http://www.baidu.com，这个就是服务器的地址" target="_blank" rel="noopener">www.baidu.com，这个就是服务器的地址</a></li>
<li><strong>path</strong>：主机资源的具体地址，如目录和文件名等</li>
<li>parameters：具体条件下访问</li>
</ul>
<p>例：</p>
<ul>
<li><p><a href="http://www.baidu.com:80" target="_blank" rel="noopener">http://www.baidu.com:80</a></p>
</li>
<li><p><a href="https://www.baidu.com:443" target="_blank" rel="noopener">https://www.baidu.com:443</a></p>
<p>这两个 URL 都可以打开网页，区别在于一个是 http 协议，一个是 https 协议。</p>
<p>http 协议默认使用的端口是 80，https 协议默认使用的端口是 443。</p>
<p>每一个 URL 的背后，其实都是对应着一台服务器的，甚至成千上万台。</p>
</li>
</ul>
<h3 id="审查元素"><a href="#审查元素" class="headerlink" title="审查元素"></a>审查元素</h3><p>在网页处右键单击，找到检查/查看元素</p>
<p>elements下为html</p>
<p><strong>浏览器作为客户端从服务器端获取信息，然后将信息解析，并展示给我们。</strong>我们可以在本地修改 HTML 信息，为网页”整容”，但是我们修改的信息不会回传到服务器，服务器存储的 HTML 信息不会改变。 </p>
<h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><ul>
<li><p>网络爬虫的第一步就是根据 URL ，获取网页的 HTML 信息。</p>
<p>在 Python3 中，可以使用<strong>urllib.request</strong>和 <strong>requests</strong> 进行网页爬取。</p>
<p>urllib 库是 Python 内置</p>
<p>requests 库是第三方库 </p>
</li>
<li><p>requests库的基础方法：</p>
<p><img alt data-src="/images/20200420234928203.png" src="/img/loading.gif" class="lazyload"> </p>
</li>
</ul>
<h1 id="（二）网络小说下载"><a href="#（二）网络小说下载" class="headerlink" title="（二）网络小说下载"></a>（二）网络小说下载</h1><p>爬取：文字、图片、音乐、视频 </p>
<p>目标网站：小说网站，“新笔趣阁”：<a href="https://www.xsbiquge.com/，" target="_blank" rel="noopener">https://www.xsbiquge.com/，</a> 只支持在线浏览，不支持小说打包下载。</p>
<h2 id="爬虫步骤"><a href="#爬虫步骤" class="headerlink" title="爬虫步骤"></a>爬虫步骤</h2><ul>
<li><p>发起请求：首先明确如何发起 HTTP 请求，获取到数据。 requests</p>
</li>
<li><p>解析数据：提取出目标数据。</p>
<p>解析数据工具有很多，比如xpath、Beautiful Soup、正则表达式等。本文使用一个简单的经典小工具，Beautiful Soup来解析数据。</p>
<p>Beautiful Soup 讲解——<a href="https://blog.csdn.net/c406495762/article/details/71158264" target="_blank" rel="noopener">https://blog.csdn.net/c406495762/article/details/71158264</a> </p>
<p>官方中文教程—— <a href="https://beautifulsoup.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">https://beautifulsoup.readthedocs.io/zh_CN/latest/</a> </p>
</li>
<li><p>保存数据：将目标数据保存下载，即文本保存。</p>
</li>
</ul>
<h2 id="爬取小说内容"><a href="#爬取小说内容" class="headerlink" title="爬取小说内容"></a>爬取小说内容</h2><h3 id="发起请求"><a href="#发起请求" class="headerlink" title="发起请求"></a>发起请求</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    target = <span class="string">'https://www.xsbiquge.com/97_97019/228839.html'</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    print(req.text)</span><br></pre></td></tr></tbody></table></figure></div>


<ul>
<li>我们很轻松地获取了 HTML 信息，里面有我们想要的小说正文内容，但是也包含了一些其他内容，我们并不关心 div 、br 这些 HTML 标签。</li>
</ul>
<h3 id="解析数据"><a href="#解析数据" class="headerlink" title="解析数据"></a>解析数据</h3><p>使用 Beautiful Soup 进行解析，把正文内容从众多的HTML标签中提取出来。</p>
<ul>
<li>审查元素，查看目标页面，发现文章内容都在一个html标签下面—— < div id=”content” > == $0</li>
<li>div 为 html标签，html标签是html语言中最基本的单位，负责存放不同的内容。</li>
<li>id为div标签的属性，content是属性值，一个属性对应一个属性值。</li>
<li>属性用于区分不同的div标签，id可以理解为这个div的身份。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 发起请求</span></span><br><span class="line">    target = <span class="string">'https://www.xsbiquge.com/97_97019/228839.html'</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    html = req.text</span><br><span class="line">    <span class="comment"># 解析数据</span></span><br><span class="line">    bs = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># 找到id属性为content的div标签</span></span><br><span class="line">    texts = bs.find(<span class="string">'div'</span>, id=<span class="string">'content'</span>)</span><br><span class="line">    print(texts)</span><br></pre></td></tr></tbody></table></figure></div>


<p>可以看到，正文内容已经顺利提取，但是里面还有一些 div 和 br 这类标签，需要进一步清洗数据。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    target = <span class="string">'https://www.xsbiquge.com/97_97019/228839.html'</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    html = req.text</span><br><span class="line">    bs = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    texts = bs.find(<span class="string">'div'</span>, id=<span class="string">'content'</span>)</span><br><span class="line">    <span class="comment"># 进一步处理</span></span><br><span class="line">    <span class="comment"># texts.text 是提取所有文字，然后再使用 strip 方法去掉回车</span></span><br><span class="line">    <span class="comment"># 最后使用 split 方法根据 \xa0 切分数据，因为每一段的开头，都有四个空格</span></span><br><span class="line">    print(texts.text.strip().split(<span class="string">'\xa0'</span>*<span class="number">4</span>))</span><br></pre></td></tr></tbody></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">['郑阳第十三中学，高三三班教室。', '“砰！”', '试卷砸在讲台桌上。', '一位戴着眼镜的中年女老师，瞪圆的眼睛仿佛从眼镜里凸出，拧着的眉头形成一个川字，她朝着班级里所有人大声说道，“上学期的期末考试，你们这个班，数学平均成绩是最差的!”', '“全班只有十六个人及格，有些人的分数还考不到一半儿，我不知道是怎么回事，有些题是比较难，但大部分题目都很简单，该拿的分一定要拿到！”', '“新学期马上开始了，你们也马上进入高三，面临高考，该怎么办心里也有点数！”', '“这节课我们还是做题、讲题，巩固一下高一、高二的知识点。”', '“前面的时间，把选择、填空都做掉，后面我们针对难题做讲解——”', '女老师说话间紧盯一个方向，音调越来越大，最后猛的爆发出来，“赵奕！赵奕！还趴着？还睡觉？我说这么大声，还叫不醒你？”', '“赵奕！赵奕……”', '全班发出哄笑。', '赵奕慢慢抬起了头，无力的揉了揉眼，眼神中充满了迷惑，似乎还在回味梦中的余韵，没有完全清醒过来。', '“赵奕，醒醒！牛魔王怒了！”旁边传来个好笑的提醒。', '赵奕扭过头。', '那是个带眼镜的瘦子，看上去有些猥琐，但感觉非常的面熟，却怎么也叫不出名字。', '瞬间，怪异涌上心头。', '赵奕呆愣着左看右看，头脑依旧不清醒，有些搞不懂情况。', '他再次扭头看向眼镜瘦子。', '伸手过去，对着胳膊！', '用力一捏！', '“哎呦！”眼镜瘦子疼的呲牙，“赵奕，你干什么！”', '“有反应！”', '赵奕震惊的肯定了一件事--不是梦！', '他穿越了！', '回到了十几年前的高中时代！', '十几年后的赵奕，和大多数人一样，在上学、上班中厮混着。', '学业，平庸。', '工作，庸碌。', '父母积攒了一辈子的财富，只刚够付个房屋首付，每天不断辛苦的加班，也只在偿还贷款的同时，勉强维持着相对节俭的生活。', '巨大的生活压力下，年少时的梦想早已淡忘，追求的目标也变得庸俗，偶尔和朋友聚会，一起吃饭、喝酒、打牌，就成为了唯一的放松方式。', '不知不觉间，他活成了年少时最讨厌的样子。', '当夜深人静的时候，偶尔回忆人生，心中的憧憬只剩下遗憾，“中学应该好好学习，能考上个顶尖大学，未来就会变得不同！”', '“大学应该好好学习，再读个名校、硕士也能改变人生！”', '“现在，穿越了？回到了从前？竟然真的能回到高中？”', '赵奕终于回过神来，目光正要聚焦到讲台，就听到怪异的电子音--', '【叮咚！】', '【学霸系统开启中……】', '他感觉脑子里出现了个东西，好像是个传说中的系统？', '电子音还在继续--', '【你获得了初始能力《因果律》！】', '【《因果律》：你能够依托现实世界的关联，在拥有正确选项的提问中，找出其中的正确选项。】', '赵奕沉浸于电子音介绍时，坐在那里一动不动，眼睛重新闭合起来。', '周围同学好笑的看着，“赵奕又睡过去了？”', '“厉害啊！睁着眼，这个动作……也能睡着！”', '“赵奕，醒醒！”', '“醒醒！”', '旁边戴眼镜的猥琐瘦子，报复式的用力推了一把。', '赵奕歪着身体差点摔在地上，双手撑地用力坐起来，扭头怒瞪起眼睛呵道，“你干什么！孙——？”', '他卡住忘了名字。', '“哈哈哈……”', '班级里响起轰然大笑。', '牛老师气的捏断了粉笔，风风火火几步冲过来，瞪圆的大眼满是怒火，铿锵有力地话语，震得耳畔发出嗡嗡响，“赵——！', '“——奕！”', '她把手里的试卷拍在赵奕了面前，“今天，你就当是考试。要是得分不及格，就罚你把题目抄十遍，错题抄二十遍！”', '“还有！”', '“叫你的家长来！”', '考试、罚抄写、叫家长。', '三连啊！', '赵奕呆愣愣的看着牛老师，完全不知道该做什么反应。', '牛老师气呼呼的回去，把试卷分发给第一排。', '孙亮的脑袋凑过来，幸灾乐祸的调侃道，“坦白交代，昨晚是不是想着孙佳丽，然后，嘿嘿嘿……就没睡好？”', '“孙佳丽在二班，也见不到，太远了，不然考虑一下我们晓晴？就在你前面，随时能看见。”', '孙亮的声音不大不小，刚好让前面的林晓晴听到。', '林晓晴个子高高的，校服的打扮盖住所有内涵，长辫子翘在脑后，浑身充满了青春的英气。', '作为一个高中女生，她的性格不能说恶劣，也远谈不上温柔。', '此时，林晓晴身体扭过来，音调仿佛从嘴里挤出来，“行啊！猴子！拿我开涮？正好没人追我，我也体验一下被追的感觉。”', '她嘴里说着想被追，却举起拳头挥了挥，以威胁性的语调问道，“猴子，你要不要试试？”', '“算了，算了！”', '孙亮讨好式的哈哈笑，连续摆手指向赵奕，“林女侠，这个宝贵的机会还是留给我们赵大侠吧！”', '“哼！”', '林晓晴扫了一眼赵奕，不在意的哼着扭过头。', '赵奕听着两人的对话，用力的扶了扶额，哪怕是把孙亮的名字忘了，他也能直接叫出林晓晴的名字，林晓晴留给他的印象太深刻了。', '林晓晴一直都是他的前桌，学习成绩班里第一，自尊心很强、争强好胜是一把手，她看似瘦瘦弱弱的，竖起的长辫子满是青春气息，实际上是个真正的女汉子。', '她真的很猛！', '上高一的时候，有个学长向林晓晴当众告白，林晓晴觉得很丢脸，恼羞成怒把那个学长揍了一顿，可怜的学长因为太丢脸不得已转学走了。', '从那以后，再没人敢追林晓晴了。', '试卷传了过来。', '赵奕已经有试卷了，只是帮忙把试卷传到后排，他也把注意力放在试卷上。', '赵奕低头看着试卷，有一种新奇的感觉，他下定决心努力一把，“多了十几年的记忆，连高等数学都及格了，普通高中数学题还能难住我？”', '看题。', '第一道选择题……？', 'What？', '还没有看到结尾，内心就受到了999+的打击。', '十几年了！', '高中的知识能忘的早就忘光了，生活基本用不到的复杂数学就更惨了。', 'π都只知道是圆周率，要不要换算成3.14？', '还有，e是啥？', '“就现在这水平，还不如以前呢！”赵奕想到已经上了高三，顿时感到了巨大的压力。', '他看到了结尾的括号。', '这时脑海产生了一种奇怪的感觉，似乎只要使用一种能力，就能够直接知道答案选项？', '赵奕满是新奇的感受着，他很确定自己的感觉没错。', '再看向试卷就完全不同了。', '卷子上的选择题，大部分他根本不会做，却知道能通过一种方式，来知道题目的正确答案？', '赵奕稍稍有点不习惯，但他马上抓住了重点--', '看不懂题却能知道答案！', '“这就是学霸系统赋予的能力？”', '【打开系统！】', '一个念头之下，脑海里就出现一组数据--', '【姓名：赵奕。】', '【脑域开发度：5.3%】', '【智慧：60。】', '【精力：100/102。】', '【学习币:0。】', '【能力：《因果律》。（激活下一阶段能力，需要消耗学习币1000。）】', '系统里的个人数据并不多，针对每一项数据内容，仔细注意一下就知道用处。', '脑域开发度，对应大脑运用思考的活跃细胞比例，直接影响智慧、精力等属性，甚至能关联到身体状况。', '智慧，差不多等同于智商，六十的评价刚刚好及格。', '精力和常人的理解一样。', '每个人的精力都是有限的，长期用脑会感觉疲惫，《因果律》能力消耗的就是精力，使用能力比正常用脑解题，消耗的精力高的多。', '学习币就像是金钱，能提升专注力，也能补充消耗的精力，获取方式和日常的行为有关。', '赵奕了解个大概以后，重新看向试卷上的题目，迫不及待的试验起能力。', '第一题。', '“已知集合A={x||4x-1|>……则A+B的区间是？”', '【《因果律》！】', '【答案：C。】', '“都不用仔细看选项，就直接知道答案是C！”', '赵奕深吸一口气，把答案填在括号里，他也同时注意系统的个人数据，面板上的精力消耗了1点。', '下一题。', '“若复数a+2i/1+2i（……则实数a的值为？”', '【《因果律》！】', '【答案：A。】', '下一题。', '“……”', '“……”', '赵奕一道道的读题、浏览选项，以平均不到十秒一题的速度，快速做完了十道选择题。', '再往下就尴尬了。', '目前正规高考的试卷中，选择题只占其中的三分之一，也就是总和五十分。', '牛老师说只做‘小题’，也包括选择后面的填空。', '“不过……”', '赵奕仔细计算了下，十道选择题是五十分，填空六个是二十四分。', '50/74=？', '大于三分之二？', '及格了！', '赵奕顿时轻呼了口气，放松下来就感到了疲惫，扫了一眼精力属性，惊讶的发现消耗了十六点精力？', '太快了吧？', '十道选择题就消耗十六点精力，换成英语试卷上那么多选择题，精力榨到的负值都不够啊！', '“虽然能力很好，但消耗也是个问题。”', '赵奕仔细琢磨着，疲乏的伸了个懒腰，忽然感觉到手肘上的柔软，有些奇怪的扭过头。', '一个黑影。', '壮实！', '瞪大的牛眼！', '牛魔王呆愣的看着赵奕，脸色由白转红、再由红转黑，发抖的身体仿佛酝酿着火山爆发的威力。', '【撩妹，目标：牛莲花，学习币+1。】', '赵奕脖子僵硬的扭回来，看向试卷装作什么也没发生。', '就听到身后愤怒的吼声--', '“赵奕！”', '“上课睡觉！做题不认真！影响同学！态度不端正……”', '牛老师吼了一连串，最后一指教室门口，“出去！走廊里罚站！”', '“是，是！”', '赵奕尴尬的站起来，仿佛是解放了般，飞速冲出了教室。']</span><br></pre></td></tr></tbody></table></figure></div>


<p>所有的内容，已经清洗干净，要想下载整本小说，我们就要获取每个章节的链接。</p>
<p>分析下小说目录，发现，所有的章节信息，都存放到了 id 属性为 list 的 div 标签下的 a 标签内。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    target = <span class="string">'https://www.xsbiquge.com/97_97019/'</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    html = req.text</span><br><span class="line">    bs = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># 找到 id 属性为 list 的 div 标签</span></span><br><span class="line">    chapters = bs.find(<span class="string">'div'</span>, id=<span class="string">'list'</span>)</span><br><span class="line">    <span class="comment"># 在找到的 div 标签里，再提取出所有 a 标签</span></span><br><span class="line">    chapters = chapters.find_all(<span class="string">'a'</span>)</span><br><span class="line">    <span class="keyword">for</span> chapter <span class="keyword">in</span> chapters:</span><br><span class="line">        print(chapter)</span><br></pre></td></tr></tbody></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"><a href="/97_97019/228839.html">第一章 开局就是数学</a></span><br><span class="line"><a href="/97_97019/228840.html">第二章 做题全靠蒙</a></span><br><span class="line"><a href="/97_97019/228841.html">第三章 英语，可是强项！</a></span><br><span class="line"><a href="/97_97019/228842.html">第四章 唯女子与小人难养也</a></span><br><span class="line"><a href="/97_97019/231688.html">第五章 知识就是金钱</a></span><br><span class="line"><a href="/97_97019/231689.html">第六章 二十块的演讲稿</a></span><br><span class="line"><a href="/97_97019/231690.html">第七章 求学是为了什么？</a></span><br><span class="line"><a href="/97_97019/231691.html">第八章 世界上最悲哀的事</a></span><br><span class="line"><a href="/97_97019/235223.html">第九章 独特的实验方式</a></span><br><span class="line"><a href="/97_97019/236120.html">第十章 单身女青年不好惹</a></span><br><span class="line"><a href="/97_97019/236981.html">感谢章节</a></span><br><span class="line"><a href="/97_97019/237161.html">第十一章 变身人气校草</a></span><br><span class="line"><a href="/97_97019/238702.html">第十二章 你笑起来真好看</a></span><br><span class="line"><a class="empty" href="/97_97019/240314.html">第十三章 没人敢追的女孩儿</a></span><br></pre></td></tr></tbody></table></figure></div>


<p>可以看到章节链接和章节名我们已经提取出来，但是还需要进一步解析</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    server = <span class="string">'https://www.xsbiquge.com'</span></span><br><span class="line">    target = <span class="string">'https://www.xsbiquge.com/97_97019/'</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    html = req.text</span><br><span class="line">    bs = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    chapters = bs.find(<span class="string">'div'</span>, id=<span class="string">'list'</span>)</span><br><span class="line">    chapters = chapters.find_all(<span class="string">'a'</span>)</span><br><span class="line">    <span class="keyword">for</span> chapter <span class="keyword">in</span> chapters:</span><br><span class="line">        <span class="comment"># 提取href属性</span></span><br><span class="line">        url = chapter.get(<span class="string">'href'</span>)</span><br><span class="line">        <span class="comment"># 提取章节名</span></span><br><span class="line">        print(chapter.string)</span><br><span class="line">        <span class="comment"># 链接</span></span><br><span class="line">        print(server + url)</span><br></pre></td></tr></tbody></table></figure></div>

<pre><code>第一章 开局就是数学
https://www.xsbiquge.com/97_97019/228839.html
第二章 做题全靠蒙
https://www.xsbiquge.com/97_97019/228840.html
第三章 英语，可是强项！
https://www.xsbiquge.com/97_97019/228841.html
第四章 唯女子与小人难养也
https://www.xsbiquge.com/97_97019/228842.html
第五章 知识就是金钱
https://www.xsbiquge.com/97_97019/231688.html
第六章 二十块的演讲稿
https://www.xsbiquge.com/97_97019/231689.html
第七章 求学是为了什么？
https://www.xsbiquge.com/97_97019/231690.html
第八章 世界上最悲哀的事
https://www.xsbiquge.com/97_97019/231691.html
第九章 独特的实验方式
https://www.xsbiquge.com/97_97019/235223.html
第十章 单身女青年不好惹
https://www.xsbiquge.com/97_97019/236120.html
感谢章节
https://www.xsbiquge.com/97_97019/236981.html
第十一章 变身人气校草
https://www.xsbiquge.com/97_97019/237161.html
第十二章 你笑起来真好看
https://www.xsbiquge.com/97_97019/238702.html
第十三章 没人敢追的女孩儿
https://www.xsbiquge.com/97_97019/240314.html</code></pre><h3 id="整合代码，保存数据"><a href="#整合代码，保存数据" class="headerlink" title="整合代码，保存数据"></a>整合代码，保存数据</h3><ul>
<li>安装 tqdm 显示下载进度</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于每一个链接，获取文章内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span><span class="params">(target)</span>:</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    html = req.text</span><br><span class="line">    bf = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    texts = bf.find(<span class="string">'div'</span>, id=<span class="string">'content'</span>)</span><br><span class="line">    content = texts.text.strip().split(<span class="string">'\xa0'</span>*<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    server = <span class="string">'https://www.xsbiquge.com'</span></span><br><span class="line">    book_name = <span class="string">'规则系学霸.txt'</span></span><br><span class="line">    target = <span class="string">'https://www.xsbiquge.com/97_97019/'</span></span><br><span class="line">    req = requests.get(url = target)</span><br><span class="line">    req.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    html = req.text</span><br><span class="line">    chapter_bs = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    chapters = chapter_bs.find(<span class="string">'div'</span>, id=<span class="string">'list'</span>)</span><br><span class="line">    chapters = chapters.find_all(<span class="string">'a'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对每个链接 获取数据并写入</span></span><br><span class="line">    <span class="keyword">for</span> chapter <span class="keyword">in</span> tqdm(chapters):</span><br><span class="line">        <span class="comment"># 章节名称</span></span><br><span class="line">        chapter_name = chapter.string</span><br><span class="line">        <span class="comment"># 章节链接</span></span><br><span class="line">        url = server + chapter.get(<span class="string">'href'</span>)</span><br><span class="line">        <span class="comment"># 章节内容</span></span><br><span class="line">        content = get_content(url)</span><br><span class="line">        <span class="comment"># 写入</span></span><br><span class="line">        <span class="keyword">with</span> open(book_name, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(chapter_name)</span><br><span class="line">            f.write(<span class="string">'\n'</span>)</span><br><span class="line">            f.write(<span class="string">'\n'</span>.join(content))</span><br><span class="line">            f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure></div>

<pre><code>100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:41<00:00,  2.93s/it]</code></pre><p>作者：注意并发量，勿给服务器带来过多的压力。</p>
<ul>
<li>每秒钟下载 1 个章节，服务器承受的压力大约 1qps，意思就是，一秒钟请求一次。</li>
<li>如果我们 1 秒同时下载 1416 个章节，那么服务器将承受大约 1416 qps 的压力，这还是仅仅你发出的并发请求数，再算上其他的用户的请求，并发量可能更多。</li>
<li>如果服务器资源不足，这个并发量足以一瞬间将服务器“打死”，特别是一些小网站，都很脆弱。</li>
<li>过大并发量的爬虫程序，相当于发起了一次 CC 攻击，并不是所有网站都能承受百万级别并发量的。</li>
<li>所以，写爬虫，一定要谨慎，勿给服务器增加过多的压力，满足我们的获取数据的需求就够了。</li>
</ul>
</body></html></div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/11/21/2020-11-21-%E8%9B%8B%E5%A3%B3%E5%85%AC%E5%AF%93%E7%A7%9F%E6%88%BF%E4%BF%A1%E6%81%AF%E7%88%AC%E5%8F%96/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>蛋壳公寓租房信息爬取</span></div></a></div><div class="next-post pull_right"><a href="/2020/08/22/2020-08-22-%E7%88%AC%E8%99%AB1&amp;2%EF%BC%88%E5%B0%8F%E8%AF%B4%E4%B8%8B%E8%BD%BD%EF%BC%89/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>爬虫1&amp;2（小说下载）</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/22/2020-08-22-爬虫1&2（小说下载）/" title="爬虫1&2（小说下载）"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-22</div><div class="relatedPosts_title">爬虫1&2（小说下载）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/11/21/2020-11-21-蛋壳公寓租房信息爬取/" title="蛋壳公寓租房信息爬取"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-11-21</div><div class="relatedPosts_title">蛋壳公寓租房信息爬取</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Iyin</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script id="canvas_nest" color="189,207,69" opacity="0.9" zIndex="-1" count="70" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>